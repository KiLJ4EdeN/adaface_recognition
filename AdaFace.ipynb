{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# installs\n",
        "!pip install -q pytorch-lightning==1.8.6"
      ],
      "metadata": {
        "id": "0EUSK9Y_YRLE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEXmYtYMWFfh",
        "outputId": "78a41b1b-d582-4d64-a1e2-cefb440633ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AdaFace' already exists and is not an empty directory.\n",
            "/content/AdaFace\n",
            "assets\t    dataset\t       img1.jpg      net.py\t  README_TRAIN.md   utils.py\n",
            "config.py   evaluate_utils.py  inference.py  pretrained   requirements.txt  validation_hq\n",
            "convert.py  face_alignment     LICENSE\t     __pycache__  scripts\t    validation_lq\n",
            "data.py     head.py\t       main.py\t     README.md\t  train_val.py\t    validation_mixed\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mk-minchul/AdaFace\n",
        "%cd AdaFace\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os\n",
        "import net\n",
        "import torch\n",
        "import gdown\n",
        "import numpy as np\n",
        "from face_alignment import align\n",
        "from inference import load_pretrained_model, to_input"
      ],
      "metadata": {
        "id": "_7j3BNzrWgbf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download model\n",
        "!mkdir -p pretrained\n",
        "url = \"https://drive.google.com/uc?id=1eUaSHG4pGlIZK7hBkqjyp2fc2epKoBvI\"\n",
        "output = \"pretrained/adaface_ir50_ms1mv2.ckpt\"\n",
        "gdown.download(url, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "66MWCB3YW727",
        "outputId": "0fb6bdcc-8e00-4a5a-baba-bf91c619aad1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1eUaSHG4pGlIZK7hBkqjyp2fc2epKoBvI\n",
            "From (redirected): https://drive.google.com/uc?id=1eUaSHG4pGlIZK7hBkqjyp2fc2epKoBvI&confirm=t&uuid=6f739219-45a9-454c-81f8-098c8d490b60\n",
            "To: /content/AdaFace/pretrained/adaface_ir50_ms1mv2.ckpt\n",
            "100%|██████████| 700M/700M [00:04<00:00, 145MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pretrained/adaface_ir50_ms1mv2.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adaface_models = {\n",
        "    'ir_50':\"pretrained/adaface_ir50_ms1mv2.ckpt\",\n",
        "}\n",
        "\n",
        "def load_pretrained_model(architecture='ir_50'):\n",
        "    # load model and pretrained statedict\n",
        "    assert architecture in adaface_models.keys()\n",
        "    model = net.build_model(architecture)\n",
        "    statedict = torch.load(adaface_models[architecture])['state_dict']\n",
        "    model_statedict = {key[6:]:val for key, val in statedict.items() if key.startswith('model.')}\n",
        "    model.load_state_dict(model_statedict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def to_input(pil_rgb_image):\n",
        "    np_img = np.array(pil_rgb_image)\n",
        "    brg_img = ((np_img[:,:,::-1] / 255.) - 0.5) / 0.5\n",
        "    tensor = torch.tensor([brg_img.transpose(2,0,1)]).float()\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "GmbhKgAIWWrN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    model = load_pretrained_model('ir_50')\n",
        "    feature, norm = model(torch.randn(2,3,112,112))\n",
        "    # add some images here and there\n",
        "    test_image_path = '/content/images'\n",
        "    features = []\n",
        "    for fname in sorted(os.listdir(test_image_path)):\n",
        "        path = os.path.join(test_image_path, fname)\n",
        "        aligned_rgb_img = align.get_aligned_face(path)\n",
        "        bgr_tensor_input = to_input(aligned_rgb_img)\n",
        "        feature, _ = model(bgr_tensor_input)\n",
        "        features.append(feature)\n",
        "\n",
        "    similarity_scores = torch.cat(features) @ torch.cat(features).T\n",
        "    print(similarity_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9qHzmI1an8M",
        "outputId": "a201fc2e-c996-40a2-af81-7a6ebfe245e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/AdaFace/face_alignment/mtcnn_pytorch/src/matlab_cp2tform.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  r, _, _, _ = lstsq(X, U)\n",
            "<ipython-input-5-7bdc3490688e>:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  tensor = torch.tensor([brg_img.transpose(2,0,1)]).float()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.5145],\n",
            "        [0.5145, 1.0000]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}